{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:20:49.656386Z",
     "iopub.status.busy": "2023-08-25T12:20:49.655702Z",
     "iopub.status.idle": "2023-08-25T12:20:49.662200Z",
     "shell.execute_reply": "2023-08-25T12:20:49.661236Z",
     "shell.execute_reply.started": "2023-08-25T12:20:49.656355Z"
    },
    "id": "r1tp9bncYFH_"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:35.934067Z",
     "iopub.status.busy": "2023-08-25T12:21:35.933661Z",
     "iopub.status.idle": "2023-08-25T12:21:35.995784Z",
     "shell.execute_reply": "2023-08-25T12:21:35.994821Z",
     "shell.execute_reply.started": "2023-08-25T12:21:35.934034Z"
    },
    "id": "ZEXVK9GfYSPg"
   },
   "outputs": [],
   "source": [
    "data=pd.read_fwf(\"C:/Users/cansh/Downloads/dialogs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:37.182220Z",
     "iopub.status.busy": "2023-08-25T12:21:37.181359Z",
     "iopub.status.idle": "2023-08-25T12:21:37.211866Z",
     "shell.execute_reply": "2023-08-25T12:21:37.208647Z",
     "shell.execute_reply.started": "2023-08-25T12:21:37.182174Z"
    },
    "id": "azX3Mm_bfBt-",
    "outputId": "e2d208a4-b301-42ec-a9a1-eed4e7e13383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hi, how are you doing?\\ti'm fine. how about yourself? Unnamed: 1 Unnamed: 2  \\\n",
      "0  i'm fine. how about yourself?\\ti'm pretty good...           NaN        NaN   \n",
      "1  i'm pretty good. thanks for asking.\\tno proble...           NaN        NaN   \n",
      "2  no problem. so how have you been?\\ti've been g...           NaN        NaN   \n",
      "3  i've been great. what about you?\\ti've been go...           NaN        NaN   \n",
      "4  i've been good. i'm in school right now.\\twhat...           NaN        NaN   \n",
      "\n",
      "  Unnamed: 3  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:38.136770Z",
     "iopub.status.busy": "2023-08-25T12:21:38.136330Z",
     "iopub.status.idle": "2023-08-25T12:21:38.144624Z",
     "shell.execute_reply": "2023-08-25T12:21:38.142977Z",
     "shell.execute_reply.started": "2023-08-25T12:21:38.136736Z"
    },
    "id": "vhp8lz3HgBs_"
   },
   "outputs": [],
   "source": [
    "text=data['hi, how are you doing?\\ti\\'m fine. how about yourself?'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:39.763607Z",
     "iopub.status.busy": "2023-08-25T12:21:39.762888Z",
     "iopub.status.idle": "2023-08-25T12:21:39.920889Z",
     "shell.execute_reply": "2023-08-25T12:21:39.919923Z",
     "shell.execute_reply.started": "2023-08-25T12:21:39.763572Z"
    },
    "id": "HqayIJ6pnmW6",
    "outputId": "9727a691-1b55-4615-ee92-e24f77ab56fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[31, 660, 37, 33, 612, 31, 155, 43, 247, 23, 495],\n",
       " [31, 155, 43, 247, 23, 495, 28, 169, 20, 37, 13, 2, 99],\n",
       " [28, 169, 20, 37, 13, 2, 99, 100, 99, 104, 9, 33, 2],\n",
       " [100, 99, 104, 9, 33, 2, 100, 99, 43, 31, 15, 93, 67, 113],\n",
       " [100, 99, 43, 31, 15, 93, 67, 113, 9, 93, 8, 2, 36, 4],\n",
       " [9, 93, 8, 2, 36, 4, 1, 36, 4, 808],\n",
       " [1, 36, 4, 808, 8, 2, 21, 6, 54],\n",
       " [8, 2, 21, 6, 54, 18, 86, 18, 5, 48, 149, 1522],\n",
       " [18, 86, 18, 5, 48, 149, 1522, 43, 809, 46, 93],\n",
       " [43, 809, 46, 93, 141, 2, 135, 85]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "seq = tokenizer.texts_to_sequences(text)\n",
    "seq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:40.797935Z",
     "iopub.status.busy": "2023-08-25T12:21:40.797420Z",
     "iopub.status.idle": "2023-08-25T12:21:40.849207Z",
     "shell.execute_reply": "2023-08-25T12:21:40.848011Z",
     "shell.execute_reply.started": "2023-08-25T12:21:40.797893Z"
    },
    "id": "Ve0nyPnuphWf",
    "outputId": "030fa661-4c52-4c80-dea6-40fb00a75d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Single Words Dropped are: 0\n"
     ]
    }
   ],
   "source": [
    "#tokenizer.word_index\n",
    "X = []\n",
    "y = []\n",
    "total_words_dropped = 0\n",
    "\n",
    "for i in seq:\n",
    "    if len(i) > 1:\n",
    "        for index in range(1, len(i)):\n",
    "            X.append(i[:index])\n",
    "            y.append(i[index])\n",
    "    else:\n",
    "        total_words_dropped += 1\n",
    "\n",
    "print(\"Total Single Words Dropped are:\", total_words_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:43.169387Z",
     "iopub.status.busy": "2023-08-25T12:21:43.168225Z",
     "iopub.status.idle": "2023-08-25T12:21:43.391057Z",
     "shell.execute_reply": "2023-08-25T12:21:43.389997Z",
     "shell.execute_reply.started": "2023-08-25T12:21:43.169341Z"
    },
    "id": "3WEShhFMqUZV"
   },
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:44.661857Z",
     "iopub.status.busy": "2023-08-25T12:21:44.661467Z",
     "iopub.status.idle": "2023-08-25T12:21:44.669344Z",
     "shell.execute_reply": "2023-08-25T12:21:44.668103Z",
     "shell.execute_reply.started": "2023-08-25T12:21:44.661823Z"
    },
    "id": "96pIerDJqgNG",
    "outputId": "a0dd9e45-80ae-406d-ce5b-4e98cce6380e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44317, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:45.527826Z",
     "iopub.status.busy": "2023-08-25T12:21:45.527429Z",
     "iopub.status.idle": "2023-08-25T12:21:45.652761Z",
     "shell.execute_reply": "2023-08-25T12:21:45.651703Z",
     "shell.execute_reply.started": "2023-08-25T12:21:45.527794Z"
    },
    "id": "nQtKilKeqjoy"
   },
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:46.619445Z",
     "iopub.status.busy": "2023-08-25T12:21:46.619048Z",
     "iopub.status.idle": "2023-08-25T12:21:46.624507Z",
     "shell.execute_reply": "2023-08-25T12:21:46.623442Z",
     "shell.execute_reply.started": "2023-08-25T12:21:46.619415Z"
    },
    "id": "i1k3MSuIqnPC"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:47.883411Z",
     "iopub.status.busy": "2023-08-25T12:21:47.883018Z",
     "iopub.status.idle": "2023-08-25T12:21:54.350418Z",
     "shell.execute_reply": "2023-08-25T12:21:54.349339Z",
     "shell.execute_reply.started": "2023-08-25T12:21:47.883378Z"
    },
    "id": "atdMo6mvqrHo"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 14),\n",
    "    tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:55.428057Z",
     "iopub.status.busy": "2023-08-25T12:21:55.427636Z",
     "iopub.status.idle": "2023-08-25T12:21:55.450926Z",
     "shell.execute_reply": "2023-08-25T12:21:55.450157Z",
     "shell.execute_reply.started": "2023-08-25T12:21:55.428020Z"
    },
    "id": "Sp8TE7J2qvao",
    "outputId": "7cb79821-8e4d-43ce-bdfd-79d088641202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 14)          35448     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 100)         46000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2532)              255732    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 427,680\n",
      "Trainable params: 427,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T12:21:56.665292Z",
     "iopub.status.busy": "2023-08-25T12:21:56.664877Z",
     "iopub.status.idle": "2023-08-25T12:21:56.687161Z",
     "shell.execute_reply": "2023-08-25T12:21:56.686015Z",
     "shell.execute_reply.started": "2023-08-25T12:21:56.665259Z"
    },
    "id": "04ivtt2nqx6p"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.004),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T12:56:04.199201Z",
     "iopub.status.busy": "2023-08-25T12:56:04.198630Z",
     "iopub.status.idle": "2023-08-25T13:16:30.011100Z",
     "shell.execute_reply": "2023-08-25T13:16:30.009906Z",
     "shell.execute_reply.started": "2023-08-25T12:56:04.199164Z"
    },
    "id": "glgxTiZzq1uE",
    "outputId": "4e1e57c1-b09e-4353-b6e6-b264b783891e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9933 - accuracy: 0.5007\n",
      "Epoch 2/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0017 - accuracy: 0.4968\n",
      "Epoch 3/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0154 - accuracy: 0.4918\n",
      "Epoch 4/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9968 - accuracy: 0.5009\n",
      "Epoch 5/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9833 - accuracy: 0.5008\n",
      "Epoch 6/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0054 - accuracy: 0.4962\n",
      "Epoch 7/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0211 - accuracy: 0.4978\n",
      "Epoch 8/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9997 - accuracy: 0.4974\n",
      "Epoch 9/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9962 - accuracy: 0.4991\n",
      "Epoch 10/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9657 - accuracy: 0.5010\n",
      "Epoch 11/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9919 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9922 - accuracy: 0.4983\n",
      "Epoch 13/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0111 - accuracy: 0.4972\n",
      "Epoch 14/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9612 - accuracy: 0.5041\n",
      "Epoch 15/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9724 - accuracy: 0.5038\n",
      "Epoch 16/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0050 - accuracy: 0.4994\n",
      "Epoch 17/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 2.0145 - accuracy: 0.4927\n",
      "Epoch 18/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 2.0088 - accuracy: 0.4945\n",
      "Epoch 19/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9731 - accuracy: 0.5026\n",
      "Epoch 20/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9336 - accuracy: 0.5100\n",
      "Epoch 21/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9844 - accuracy: 0.5021\n",
      "Epoch 22/100\n",
      "1385/1385 [==============================] - 14s 10ms/step - loss: 1.9746 - accuracy: 0.5039\n",
      "Epoch 23/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9821 - accuracy: 0.5022\n",
      "Epoch 24/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 2.0012 - accuracy: 0.4977\n",
      "Epoch 25/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9804 - accuracy: 0.5037\n",
      "Epoch 26/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9270 - accuracy: 0.5120\n",
      "Epoch 27/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9689 - accuracy: 0.5035\n",
      "Epoch 28/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9644 - accuracy: 0.5044\n",
      "Epoch 29/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9475 - accuracy: 0.5110\n",
      "Epoch 30/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9694 - accuracy: 0.5032\n",
      "Epoch 31/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9672 - accuracy: 0.5046\n",
      "Epoch 32/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9620 - accuracy: 0.5042\n",
      "Epoch 33/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9398 - accuracy: 0.5110\n",
      "Epoch 34/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0179 - accuracy: 0.4957\n",
      "Epoch 35/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9793 - accuracy: 0.5034\n",
      "Epoch 36/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9625 - accuracy: 0.5073\n",
      "Epoch 37/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9248 - accuracy: 0.5129\n",
      "Epoch 38/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9245 - accuracy: 0.5120\n",
      "Epoch 39/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9518 - accuracy: 0.5078\n",
      "Epoch 40/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9906 - accuracy: 0.5016\n",
      "Epoch 41/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9823 - accuracy: 0.5029\n",
      "Epoch 42/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9008 - accuracy: 0.5174\n",
      "Epoch 43/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9616 - accuracy: 0.5054\n",
      "Epoch 44/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9437 - accuracy: 0.5108\n",
      "Epoch 45/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9534 - accuracy: 0.5095\n",
      "Epoch 46/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9614 - accuracy: 0.5074\n",
      "Epoch 47/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9586 - accuracy: 0.5059\n",
      "Epoch 48/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9843 - accuracy: 0.5044\n",
      "Epoch 49/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8957 - accuracy: 0.5182\n",
      "Epoch 50/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9636 - accuracy: 0.5065\n",
      "Epoch 51/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9569 - accuracy: 0.5093\n",
      "Epoch 52/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9057 - accuracy: 0.5154\n",
      "Epoch 53/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9750 - accuracy: 0.5082\n",
      "Epoch 54/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9829 - accuracy: 0.5019\n",
      "Epoch 55/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9099 - accuracy: 0.5181\n",
      "Epoch 56/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9402 - accuracy: 0.5096\n",
      "Epoch 57/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9419 - accuracy: 0.5115\n",
      "Epoch 58/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8939 - accuracy: 0.5186\n",
      "Epoch 59/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9626 - accuracy: 0.5099\n",
      "Epoch 60/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 2.0152 - accuracy: 0.4982\n",
      "Epoch 61/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9986 - accuracy: 0.5023\n",
      "Epoch 62/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9091 - accuracy: 0.5159\n",
      "Epoch 63/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9354 - accuracy: 0.5150\n",
      "Epoch 64/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9484 - accuracy: 0.5087\n",
      "Epoch 65/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9495 - accuracy: 0.5093\n",
      "Epoch 66/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9182 - accuracy: 0.5143\n",
      "Epoch 67/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9662 - accuracy: 0.5081\n",
      "Epoch 68/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9292 - accuracy: 0.5125\n",
      "Epoch 69/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9164 - accuracy: 0.5141\n",
      "Epoch 70/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9643 - accuracy: 0.5073\n",
      "Epoch 71/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9167 - accuracy: 0.5159\n",
      "Epoch 72/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9112 - accuracy: 0.5186\n",
      "Epoch 73/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9030 - accuracy: 0.5188\n",
      "Epoch 74/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.8998 - accuracy: 0.5178\n",
      "Epoch 75/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9284 - accuracy: 0.5160\n",
      "Epoch 76/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9265 - accuracy: 0.5183\n",
      "Epoch 77/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9237 - accuracy: 0.5143\n",
      "Epoch 78/100\n",
      "1385/1385 [==============================] - 12s 8ms/step - loss: 1.9273 - accuracy: 0.5141\n",
      "Epoch 79/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9300 - accuracy: 0.5146\n",
      "Epoch 80/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9388 - accuracy: 0.5137\n",
      "Epoch 81/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9176 - accuracy: 0.5162\n",
      "Epoch 82/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9120 - accuracy: 0.5177\n",
      "Epoch 83/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9043 - accuracy: 0.5193\n",
      "Epoch 84/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9130 - accuracy: 0.5155\n",
      "Epoch 85/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9154 - accuracy: 0.5164\n",
      "Epoch 86/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9373 - accuracy: 0.5146\n",
      "Epoch 87/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9055 - accuracy: 0.5153\n",
      "Epoch 88/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8894 - accuracy: 0.5220\n",
      "Epoch 89/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8477 - accuracy: 0.5308\n",
      "Epoch 90/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9156 - accuracy: 0.5190\n",
      "Epoch 91/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9103 - accuracy: 0.5189\n",
      "Epoch 92/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.8542 - accuracy: 0.5273\n",
      "Epoch 93/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.9623 - accuracy: 0.5086\n",
      "Epoch 94/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8993 - accuracy: 0.5191\n",
      "Epoch 95/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9025 - accuracy: 0.5205\n",
      "Epoch 96/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8670 - accuracy: 0.5242\n",
      "Epoch 97/100\n",
      "1385/1385 [==============================] - 12s 9ms/step - loss: 1.8813 - accuracy: 0.5253\n",
      "Epoch 98/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.9160 - accuracy: 0.5205\n",
      "Epoch 99/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.8705 - accuracy: 0.5264\n",
      "Epoch 100/100\n",
      "1385/1385 [==============================] - 13s 9ms/step - loss: 1.8783 - accuracy: 0.5257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ce378163790>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T13:18:19.174772Z",
     "iopub.status.busy": "2023-08-25T13:18:19.174392Z",
     "iopub.status.idle": "2023-08-25T13:18:27.442393Z",
     "shell.execute_reply": "2023-08-25T13:18:27.441354Z",
     "shell.execute_reply.started": "2023-08-25T13:18:19.174740Z"
    },
    "id": "mo4l_j6iq5FR",
    "outputId": "a2a6c938-5e18-47f6-dc74-ba4e1c702067"
   },
   "outputs": [],
   "source": [
    "model.save('asl.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T13:24:17.444228Z",
     "iopub.status.busy": "2023-08-25T13:24:17.443120Z",
     "iopub.status.idle": "2023-08-25T13:24:17.451175Z",
     "shell.execute_reply": "2023-08-25T13:24:17.450030Z",
     "shell.execute_reply.started": "2023-08-25T13:24:17.444188Z"
    },
    "id": "o63Er2b4EjOn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'you', 'the', ..., 'planes', 'bless', 'modern'], dtype='<U16')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_array = np.array(list(tokenizer.word_index.keys()))\n",
    "vocab_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "yQBPc8MGEvvq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T13:24:21.247724Z",
     "iopub.status.busy": "2023-08-25T13:24:21.246572Z",
     "iopub.status.idle": "2023-08-25T13:24:21.259432Z",
     "shell.execute_reply": "2023-08-25T13:24:21.258319Z",
     "shell.execute_reply.started": "2023-08-25T13:24:21.247683Z"
    },
    "id": "H-auajCGM4-I"
   },
   "outputs": [],
   "source": [
    "def make_prediction(text, n_words, top_n=3):\n",
    "    pred_list=[]\n",
    "    for i in range(n_words):\n",
    "        text_tokenize = tokenizer.texts_to_sequences([text])\n",
    "        text_padded = tf.keras.preprocessing.sequence.pad_sequences(text_tokenize, maxlen=14)\n",
    "\n",
    "        probabilities = model.predict(text_padded)[0]  # Assuming batch size is 1\n",
    "\n",
    "        # Get indices of top_n predictions\n",
    "        top_indices = np.argsort(probabilities)[-top_n:][::-1]\n",
    "\n",
    "        # Get corresponding words and probabilities\n",
    "        top_predictions = [(vocab_array[idx - 1], probabilities[idx]) for idx in top_indices]\n",
    "\n",
    "        print(f\"Step {i+1} predictions:\")\n",
    "        for word, probability in top_predictions:\n",
    "            print(f\"Word: {word}, Probability: {probability:.4f}\")\n",
    "            pred_list.append(word)\n",
    "        # Use the most probable prediction\n",
    "        prediction = np.argmax(probabilities)\n",
    "        prediction = str(vocab_array[prediction - 1])\n",
    "\n",
    "        text += \" \" + prediction\n",
    "\n",
    "    return pred_list\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T13:45:26.351482Z",
     "iopub.status.busy": "2023-08-25T13:45:26.350781Z",
     "iopub.status.idle": "2023-08-25T13:45:26.422138Z",
     "shell.execute_reply": "2023-08-25T13:45:26.421013Z",
     "shell.execute_reply.started": "2023-08-25T13:45:26.351444Z"
    },
    "id": "CUgSqEJQFxS_",
    "outputId": "32ed15cc-44c3-45a6-a576-f569c9ff89dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Step 1 predictions:\n",
      "Word: to, Probability: 0.9230\n",
      "Word: 80, Probability: 0.0303\n",
      "Word: elected, Probability: 0.0164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['to', '80', 'elected']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(\"\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "x30m7YKuISSn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2023-08-25T13:16:30.025549Z",
     "iopub.status.idle": "2023-08-25T13:16:30.026382Z",
     "shell.execute_reply": "2023-08-25T13:16:30.026143Z",
     "shell.execute_reply.started": "2023-08-25T13:16:30.026117Z"
    },
    "id": "Gnf06Ne0F-Xw",
    "outputId": "0c19969b-44eb-4c46-b5d8-dba51ebe7002"
   },
   "outputs": [],
   "source": [
    "text_list = []\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    out = dict[model.output]\n",
    "    \n",
    "    if not out:\n",
    "        break\n",
    "    \n",
    "    if index == 0 or text_list[index - 1] != out:  # Check if the output is different from the previous one\n",
    "        text_list.append(out)\n",
    "        index += 1\n",
    "        text_to_predict = ' '.join(text_list)  # Join the text list to form a single string\n",
    "        make_prediction(text_to_predict, 1)  # Call your make_prediction function\n",
    "        \n",
    "    elif model.output == 21:  # Check for specific condition\n",
    "        text_list.pop()\n",
    "        index -= 1\n",
    "        \n",
    "    elif model.output in [22, 23, 24]:  # Check for specific conditions\n",
    "        out = return_list[model.output - 22]\n",
    "        \n",
    "        if text_list[index - 1] != out:\n",
    "            text_list.append(out)\n",
    "            index += 1\n",
    "            text_to_predict = ' '.join(text_list)\n",
    "            make_prediction(text_to_predict, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kK9kvAulInL-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
