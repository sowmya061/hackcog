# hackcog
This repo contains everything related to this project. From the datasets to the notebooks used to train the two models, everything can be found here. :)
ABOUT:
We aim to create a sort of proof-of-concept version of a model which will assist people with speaking and hearing disabilities in communicating with humans and computers. The model can be used to convert hand gestures to write full sentences, also users will be provided with 'next-word-suggestions' which will be done through a language model trained by us. The user can choose one the the 3 suggestions or continue to enter their own words.

The model can convert the sentence formed to speech .

We have also facilitated the use of chatbots and language models like chatGPT. You can type in your sentences and directly ask your query to chatgpt.

NOTE: This is not a full-fledged product by any means and is only supposed to provide the necessary proof-of-concept.
